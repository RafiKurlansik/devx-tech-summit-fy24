{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d054513a-ce6b-48a9-9c62-948aefd97971",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Unit tests in PySpark\n",
    "Testing is a crucial part of software development that helps in identifying issues with your code early and often, thereby ensuring the reliability and robustness of the application. **Unit tests** are designed to test the independent pieces of logic that comprise your application. In general, tests look to validate that your logic is functioning as intended. **By asserting that the _actual_ output of our logic is identical to the _expected_ output, we can determine if the logic has been implemented correctly.** Ideally each test will cover exactly one piece of functionality, e.g.,  a specific data transformation or helper function.\n",
    " \n",
    " In the context of PySpark tests are usually centered around **comparing DataFrames** for expected output.  There are several dimensions by which DataFrames can be compared:\n",
    " <br><br>\n",
    " \n",
    " * Schemas\n",
    " * Columns\n",
    " * Rows \n",
    " * Entire DataFrames\n",
    "\n",
    "In this notebook, we are going to learn about unit testing PySpark applications using the Python `pytest` framework. Tests will be written using the popular `chispa` library as well as the new PySpark native testing functions available in Spark 3.5.[link] This tutorial is designed to keep it simple, so if you want to learn more about how `pytest` works we recommend taking a closer look at the official documentation [link].\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "209108c6-8c7b-400d-ab66-8c423a445e31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Working with `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f285c77-8429-4749-b045-a39867575a2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## How to structure your project with pytest\n",
    "Consider the following hypothetical project structure for a simple reporting use case:\n",
    "\n",
    "```\n",
    "├── notebooks/\n",
    "│   ├── analysis.ipynb   # report with visualizations\n",
    "├── src/\n",
    "│   ├── load_config.py   # helper functions\n",
    "│   └── cleaning.py\n",
    "├── tests/\n",
    "│   ├── main_test.py     # unit tests\n",
    "├── requirements.txt     # dependencies\n",
    "└── test-requirements.txt\n",
    "```\n",
    "\n",
    "The `notebooks/` folder contains `analysis.ipynb`, which reports on and visualizes some business data.  This notebook imports custom Python functions from both files in `src/` to help load and clean data like so:\n",
    "\n",
    "```\n",
    "from src.load_config import db_loader, config_handler\n",
    "from src.cleaning import *\n",
    "```\n",
    "\n",
    "Since our report depends on these functions to get and prepare the data correctly, we want to write tests that validate our functions are behaving as intended.  To so do, we create a `tests/` folder and include our tests there.  **`pytest` is designed to look for folders and files with \"test\" as a prefix or suffix.**  In this example our test script is called `main_test.py`, but later on you will see examples like `test_pyspark_column_equality.py`.  Both are supported and will be picked up by `pytest`. \n",
    "\n",
    "The last two files in our project are specify any dependencies for all of our code.  It is a best practice to separate testing dependencies, since we only need `pytest` to run the testing scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25e44968-8f39-46aa-821f-244fab29d402",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Invoking `pytest`\n",
    "\n",
    "`pytest` is usually run from the system command line, but it can also be executed from the context of a notebook or Python REPL.  We'll be using the latter method to invoke our tests from the Databricks editor.  This lets us make use of Spark and other configuration variables in Databricks Runtime. \n",
    "\n",
    "One limitation of this approach is that changes to the test will be cached by Python's import caching mechanism.  If we wanted to iterate on tests during a development scenario, we would need to use `dbutils.library.restartPython()` to clear the cache and pick up changes to our tests.  This tutorial has been structured to render this unnecessary, but it is important to note!\n",
    "\n",
    "In the following cell, we first make sure that all tests will run relative to our repository root directory.  Then we define `run_pytest`, a helper function to invoke a specific test file in our project.  Importantly, this function also fails the Databricks notebook cell execution if tests fail.  This ensures we surface errors whether we run these unit tests in an interactive session or as part of a Databricks Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e4d1408-8fda-45c2-a849-6270eae2db29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Run all tests in the repository root.\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "repo_root = os.path.dirname(os.path.dirname(notebook_path))\n",
    "os.chdir(f'/Workspace/{repo_root}')\n",
    "%pwd\n",
    "\n",
    "def run_pytest(pytest_path):\n",
    "  # Skip writing pyc files on a readonly filesystem.\n",
    "  sys.dont_write_bytecode = True\n",
    "\n",
    "  retcode = pytest.main([pytest_path, \"-p\", \"no:cacheprovider\"])\n",
    "\n",
    "  # Fail the cell execution if we have any test failures.\n",
    "  assert retcode == 0, 'The pytest invocation failed. See the log above for details.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c69b4a6-9722-44ed-9d9d-8bc54b5db702",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test scenarios\n",
    "#### Installing dependencies\n",
    "\n",
    "Let's ensure we install any dependencies for our tests first. To make use of them we will need to restart the Python interpreter before running any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a682af92-5428-48cf-8ac2-f5e398473c2b",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cp ../requirements.txt ~/.\n",
    "%pip install -r ~/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7202b13-2028-4a8c-a41d-ff101fbf063c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "262313ae-263a-42e1-86fd-deb83b683b38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using `chispa`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93166279-208c-40ee-85ee-c25b4433dea8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Schema equality\n",
    "\n",
    "A common data transformation task is to add or remove columns from DataFrames.  In these cases we define a function that takes a DataFrame as input, alters the schema, and returns a DataFrame as output.  In `chispa` we can test the validity of our function by using the `assert_df_equality()` function.  \n",
    "\n",
    "For example, let's say we want to compare the following two DataFrames with `assert_df_equality()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f378b29b-5806-4b5e-a501-22e570f5324a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mSchemasNotEqualError\u001B[0m                      Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2786918639959420>, line 21\u001B[0m\n",
       "\u001B[1;32m     18\u001B[0m df2 \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(data2, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum2\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Compare them\u001B[39;00m\n",
       "\u001B[0;32m---> 21\u001B[0m assert_df_equality(df1, df2)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/dataframe_comparer.py:22\u001B[0m, in \u001B[0;36massert_df_equality\u001B[0;34m(df1, df2, ignore_nullable, transforms, allow_nan_equality, ignore_column_order, ignore_row_order, underline_cells)\u001B[0m\n",
       "\u001B[1;32m     20\u001B[0m df1 \u001B[38;5;241m=\u001B[39m reduce(\u001B[38;5;28;01mlambda\u001B[39;00m acc, fn: fn(acc), transforms, df1)\n",
       "\u001B[1;32m     21\u001B[0m df2 \u001B[38;5;241m=\u001B[39m reduce(\u001B[38;5;28;01mlambda\u001B[39;00m acc, fn: fn(acc), transforms, df2)\n",
       "\u001B[0;32m---> 22\u001B[0m \u001B[43massert_schema_equality\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_nullable\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m allow_nan_equality:\n",
       "\u001B[1;32m     24\u001B[0m     assert_generic_rows_equality(\n",
       "\u001B[1;32m     25\u001B[0m         df1\u001B[38;5;241m.\u001B[39mcollect(), df2\u001B[38;5;241m.\u001B[39mcollect(), are_rows_equal_enhanced, [\u001B[38;5;28;01mTrue\u001B[39;00m], underline_cells\u001B[38;5;241m=\u001B[39munderline_cells)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/schema_comparer.py:15\u001B[0m, in \u001B[0;36massert_schema_equality\u001B[0;34m(s1, s2, ignore_nullable)\u001B[0m\n",
       "\u001B[1;32m     13\u001B[0m     assert_schema_equality_ignore_nullable(s1, s2)\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 15\u001B[0m     \u001B[43massert_basic_schema_equality\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms2\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/schema_comparer.py:27\u001B[0m, in \u001B[0;36massert_basic_schema_equality\u001B[0;34m(s1, s2)\u001B[0m\n",
       "\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     26\u001B[0m         t\u001B[38;5;241m.\u001B[39madd_row([sf1, sf2])\n",
       "\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m SchemasNotEqualError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m t\u001B[38;5;241m.\u001B[39mget_string())\n",
       "\n",
       "\u001B[0;31mSchemasNotEqualError\u001B[0m: \n",
       "+-------------------------------------------+---------------------------------------+\n",
       "|                  schema1                  |                schema2                |\n",
       "+-------------------------------------------+---------------------------------------+\n",
       "|    \u001B[34mStructField('num', LongType(), True)\u001B[31m   |  \u001B[34mStructField('num', LongType(), True)\u001B[31m |\n",
       "| StructField('letter', StringType(), True) | StructField('num2', LongType(), True) |\n",
       "+-------------------------------------------+---------------------------------------+"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mSchemasNotEqualError\u001B[0m                      Traceback (most recent call last)\nFile \u001B[0;32m<command-2786918639959420>, line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m df2 \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(data2, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum2\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Compare them\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m assert_df_equality(df1, df2)\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/dataframe_comparer.py:22\u001B[0m, in \u001B[0;36massert_df_equality\u001B[0;34m(df1, df2, ignore_nullable, transforms, allow_nan_equality, ignore_column_order, ignore_row_order, underline_cells)\u001B[0m\n\u001B[1;32m     20\u001B[0m df1 \u001B[38;5;241m=\u001B[39m reduce(\u001B[38;5;28;01mlambda\u001B[39;00m acc, fn: fn(acc), transforms, df1)\n\u001B[1;32m     21\u001B[0m df2 \u001B[38;5;241m=\u001B[39m reduce(\u001B[38;5;28;01mlambda\u001B[39;00m acc, fn: fn(acc), transforms, df2)\n\u001B[0;32m---> 22\u001B[0m \u001B[43massert_schema_equality\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_nullable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m allow_nan_equality:\n\u001B[1;32m     24\u001B[0m     assert_generic_rows_equality(\n\u001B[1;32m     25\u001B[0m         df1\u001B[38;5;241m.\u001B[39mcollect(), df2\u001B[38;5;241m.\u001B[39mcollect(), are_rows_equal_enhanced, [\u001B[38;5;28;01mTrue\u001B[39;00m], underline_cells\u001B[38;5;241m=\u001B[39munderline_cells)\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/schema_comparer.py:15\u001B[0m, in \u001B[0;36massert_schema_equality\u001B[0;34m(s1, s2, ignore_nullable)\u001B[0m\n\u001B[1;32m     13\u001B[0m     assert_schema_equality_ignore_nullable(s1, s2)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 15\u001B[0m     \u001B[43massert_basic_schema_equality\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms2\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/schema_comparer.py:27\u001B[0m, in \u001B[0;36massert_basic_schema_equality\u001B[0;34m(s1, s2)\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m         t\u001B[38;5;241m.\u001B[39madd_row([sf1, sf2])\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m SchemasNotEqualError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m t\u001B[38;5;241m.\u001B[39mget_string())\n\n\u001B[0;31mSchemasNotEqualError\u001B[0m: \n+-------------------------------------------+---------------------------------------+\n|                  schema1                  |                schema2                |\n+-------------------------------------------+---------------------------------------+\n|    \u001B[34mStructField('num', LongType(), True)\u001B[31m   |  \u001B[34mStructField('num', LongType(), True)\u001B[31m |\n| StructField('letter', StringType(), True) | StructField('num2', LongType(), True) |\n+-------------------------------------------+---------------------------------------+",
       "errorSummary": "<span class='ansi-red-fg'>SchemasNotEqualError</span>: \n+-------------------------------------------+---------------------------------------+\n|                  schema1                  |                schema2                |\n+-------------------------------------------+---------------------------------------+\n|    \u001B[34mStructField('num', LongType(), True)\u001B[31m   |  \u001B[34mStructField('num', LongType(), True)\u001B[31m |\n| StructField('letter', StringType(), True) | StructField('num2', LongType(), True) |\n+-------------------------------------------+---------------------------------------+",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chispa import assert_df_equality\n",
    "# DF with numeric and string columns\n",
    "data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "data2 = [\n",
    "        (1, 6),\n",
    "        (2, 7),\n",
    "        (3, 8),\n",
    "        (None, None)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(data2, [\"num\", \"num2\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c66d65d-2971-414d-8959-f6f26f7183e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we expected, this fails.  `chispa` makes it really clear exactly why it failed, too, specifying the precise column differences and highlighting the discrepancies in red. \n",
    "\n",
    "Let's look at that same scenario, but make sure that it passes this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c07e5cae-5d53-48c9-85e6-d1f91b45d87f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mDataFramesNotEqualError\u001B[0m                   Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2786918639959422>, line 21\u001B[0m\n",
       "\u001B[1;32m     18\u001B[0m df2 \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(data2, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mletter\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Compare them\u001B[39;00m\n",
       "\u001B[0;32m---> 21\u001B[0m assert_df_equality(df1, df2)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/dataframe_comparer.py:27\u001B[0m, in \u001B[0;36massert_df_equality\u001B[0;34m(df1, df2, ignore_nullable, transforms, allow_nan_equality, ignore_column_order, ignore_row_order, underline_cells)\u001B[0m\n",
       "\u001B[1;32m     24\u001B[0m     assert_generic_rows_equality(\n",
       "\u001B[1;32m     25\u001B[0m         df1\u001B[38;5;241m.\u001B[39mcollect(), df2\u001B[38;5;241m.\u001B[39mcollect(), are_rows_equal_enhanced, [\u001B[38;5;28;01mTrue\u001B[39;00m], underline_cells\u001B[38;5;241m=\u001B[39munderline_cells)\n",
       "\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 27\u001B[0m     \u001B[43massert_basic_rows_equality\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munderline_cells\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munderline_cells\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/rows_comparer.py:25\u001B[0m, in \u001B[0;36massert_basic_rows_equality\u001B[0;34m(rows1, rows2, underline_cells)\u001B[0m\n",
       "\u001B[1;32m     23\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     24\u001B[0m             t\u001B[38;5;241m.\u001B[39madd_row([r1, r2])\n",
       "\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m chispa\u001B[38;5;241m.\u001B[39mDataFramesNotEqualError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m t\u001B[38;5;241m.\u001B[39mget_string())\n",
       "\n",
       "\u001B[0;31mDataFramesNotEqualError\u001B[0m: \n",
       "+----------------------------+----------------------------+\n",
       "|            df1             |            df2             |\n",
       "+----------------------------+----------------------------+\n",
       "|   Row(num=1, letter='a')   |   Row(num=1, letter='d')   |\n",
       "|   Row(num=2, letter='b')   |   Row(num=2, letter='e')   |\n",
       "|   Row(num=3, letter='c')   |   Row(num=3, letter='f')   |\n",
       "| \u001B[34mRow(num=None, letter=None)\u001B[31m | \u001B[34mRow(num=None, letter=None)\u001B[31m |\n",
       "+----------------------------+----------------------------+"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mDataFramesNotEqualError\u001B[0m                   Traceback (most recent call last)\nFile \u001B[0;32m<command-2786918639959422>, line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m df2 \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame(data2, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mletter\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Compare them\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m assert_df_equality(df1, df2)\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/dataframe_comparer.py:27\u001B[0m, in \u001B[0;36massert_df_equality\u001B[0;34m(df1, df2, ignore_nullable, transforms, allow_nan_equality, ignore_column_order, ignore_row_order, underline_cells)\u001B[0m\n\u001B[1;32m     24\u001B[0m     assert_generic_rows_equality(\n\u001B[1;32m     25\u001B[0m         df1\u001B[38;5;241m.\u001B[39mcollect(), df2\u001B[38;5;241m.\u001B[39mcollect(), are_rows_equal_enhanced, [\u001B[38;5;28;01mTrue\u001B[39;00m], underline_cells\u001B[38;5;241m=\u001B[39munderline_cells)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 27\u001B[0m     \u001B[43massert_basic_rows_equality\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munderline_cells\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munderline_cells\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/rows_comparer.py:25\u001B[0m, in \u001B[0;36massert_basic_rows_equality\u001B[0;34m(rows1, rows2, underline_cells)\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m             t\u001B[38;5;241m.\u001B[39madd_row([r1, r2])\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m chispa\u001B[38;5;241m.\u001B[39mDataFramesNotEqualError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m t\u001B[38;5;241m.\u001B[39mget_string())\n\n\u001B[0;31mDataFramesNotEqualError\u001B[0m: \n+----------------------------+----------------------------+\n|            df1             |            df2             |\n+----------------------------+----------------------------+\n|   Row(num=1, letter='a')   |   Row(num=1, letter='d')   |\n|   Row(num=2, letter='b')   |   Row(num=2, letter='e')   |\n|   Row(num=3, letter='c')   |   Row(num=3, letter='f')   |\n| \u001B[34mRow(num=None, letter=None)\u001B[31m | \u001B[34mRow(num=None, letter=None)\u001B[31m |\n+----------------------------+----------------------------+",
       "errorSummary": "<span class='ansi-red-fg'>DataFramesNotEqualError</span>: \n+----------------------------+----------------------------+\n|            df1             |            df2             |\n+----------------------------+----------------------------+\n|   Row(num=1, letter='a')   |   Row(num=1, letter='d')   |\n|   Row(num=2, letter='b')   |   Row(num=2, letter='e')   |\n|   Row(num=3, letter='c')   |   Row(num=3, letter='f')   |\n| \u001B[34mRow(num=None, letter=None)\u001B[31m | \u001B[34mRow(num=None, letter=None)\u001B[31m |\n+----------------------------+----------------------------+",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chispa import assert_df_equality\n",
    "# DF with numeric and string columns\n",
    "data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "data2 = [\n",
    "        (1, \"d\"),\n",
    "        (2, \"e\"),\n",
    "        (3, \"f\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(data2, [\"num\", \"letter\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0348766-6d8c-4924-86d9-bce88b243db3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Aha! The schemas match but the DataFrames are not 100% equal.  Let's try this one more time and ensure that the DataFrames are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97f83ce0-3d20-4139-b4e9-becb193cb231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chispa import assert_df_equality\n",
    "# DF with numeric and string columns\n",
    "data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "data2 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(data2, [\"num\", \"letter\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3503773-c3da-44c8-bf58-8550755597d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "`chispa` will not return any output to the console when we run tests this way.  However, when we use `chispa` in combination with `pytest`, we will always get a complete report on how our tests fared.  To do so, we have added `tests/test_chispa_101.py` to our project.  This file contains the exact same test that we ran in the cell above, the only exception being that we wrap it in a function:\n",
    "\n",
    "```{python}\n",
    "## contents of tests/chispa/test_chispa_101.py\n",
    "\n",
    "def test_schema_mismatch_message():\n",
    "    # DF with numeric and string columns\n",
    "    data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "    df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "    \n",
    "    # DF with only numeric columns\n",
    "    data2 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "    df2 = spark.createDataFrame(data2, [\"num\", \"letter\"])\n",
    "    \n",
    "    # Compare them\n",
    "    assert_df_equality(df1, df2)\n",
    "```\n",
    "\n",
    "Let's invoke this test now using `pytest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b782cfe0-719f-44f5-adfd-2e1c85446195",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts ==============================\u001B[0m\nplatform linux -- Python 3.10.12, pytest-7.2.0, pluggy-1.0.0\nrootdir: /Workspace/Repos/dustin.vannoy@databricks.com/notebook-best-practices, configfile: pytest.ini\nplugins: anyio-3.5.0, typeguard-2.13.3\ncollected 1 item\n\ntests/chispa/test_chispa_101.py \u001B[32m.\u001B[0m\u001B[32m                                        [100%]\u001B[0m\n\n\u001B[32m============================== \u001B[32m\u001B[1m1 passed\u001B[0m\u001B[32m in 0.99s\u001B[0m\u001B[32m ===============================\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_101.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91c67837-4bcf-488b-a64d-ebf0135bcee9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Column equality\n",
    "\n",
    "In addition to adding or removing columns, a common data transformation is to update the contents of a column.  Let's take a slightly more realistic example for this case.  \n",
    "\n",
    "Say we have a helper function called `remove_non_word_characters()` which ... you guessed it, strips all non-word characters from the strings in each row. \n",
    "\n",
    "```\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Removing all non-word characters in PySpark\n",
    "def remove_non_word_characters(col):\n",
    "    return F.regexp_replace(col, \"[^\\\\w\\\\s]+\", \"\")\n",
    "```\n",
    "\n",
    "To test this unit of logic, we will take three simple steps:\n",
    "\n",
    "1. Create a DataFrame with rows that have non-word characters\n",
    "2. Apply `remove_non_word_characters()` to the DataFrame and generate a new column with clean rows\n",
    "3. Compare this DataFrame to a 2nd DataFrame with the expected output and assert that the two are equal\n",
    "\n",
    "The following cell does just that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316b9213-87ee-49cf-9226-c167f7d30701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from covid_analysis.transforms_spark import remove_non_word_characters\n",
    "from chispa import assert_column_equality\n",
    "\n",
    "# Dirty rows\n",
    "dirty_rows = [\n",
    "      (\"jo&&se\",),\n",
    "      (\"**li**\",),\n",
    "      (\"#::luisa\",),\n",
    "      (None,)\n",
    "  ]\n",
    "source_df = spark.createDataFrame(dirty_rows, [\"name\"])\n",
    "\n",
    "# Cleaned rows using function\n",
    "clean_df = source_df.withColumn(\n",
    "    \"clean_name\",\n",
    "    remove_non_word_characters(F.col(\"name\"))\n",
    ")\n",
    "\n",
    "# Expected output, should be identical to clean_df\n",
    "expected_data = [\n",
    "      (\"jo&&se\", \"jose\"),\n",
    "      (\"**li**\", \"li\"),\n",
    "      (\"#::luisa\", \"luisa\"),\n",
    "      (None, None)\n",
    "  ]\n",
    "expected_df = spark.createDataFrame(expected_data, [\"name\", \"clean_name\"])\n",
    "\n",
    "assert_df_equality(clean_df, expected_df, underline_cells=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2eccecd-762c-4d94-92a2-91fab6b33749",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looks good.  Before we invoke this test, let's consider another case:\n",
    "\n",
    "```\n",
    "data = [\n",
    "        (\"matt7\", \"matt\"),\n",
    "        (\"bill&\", \"bill\"),\n",
    "        (\"isabela*\", \"isabela\"),\n",
    "        (None, None)\n",
    "      ]\n",
    "```\n",
    "\n",
    "We have included this test case in `tests/chispa/test_chispa_column_equality.py`. \n",
    " Take a look at the `remove_non_word_characters()` function and think about it before you invoke `pytest` in the next cell.\n",
    " \n",
    " What do you think will happen? Will this test pass?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ae3d6ff-605a-4089-a74d-d2629f641534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts ==============================\u001B[0m\nplatform linux -- Python 3.10.12, pytest-7.2.0, pluggy-1.0.0\nrootdir: /Workspace/Repos/dustin.vannoy@databricks.com/notebook-best-practices, configfile: pytest.ini\nplugins: anyio-3.5.0, typeguard-2.13.3\ncollected 2 items\n\ntests/chispa/test_chispa_column_equality.py \u001B[32m.\u001B[0m\u001B[31mF\u001B[0m\u001B[31m                           [100%]\u001B[0m\n\n=================================== FAILURES ===================================\n\u001B[31m\u001B[1m__________________ test_remove_non_word_characters_nice_error __________________\u001B[0m\n\n>   \u001B[04m\u001B[91m?\u001B[39;49;00m\u001B[04m\u001B[91m?\u001B[39;49;00m\u001B[04m\u001B[91m?\u001B[39;49;00m\n\n\u001B[1m\u001B[31mtests/chispa/test_chispa_column_equality.py\u001B[0m:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndf = DataFrame[name: string, expected_name: string, clean_name: string]\ncol_name1 = 'clean_name', col_name2 = 'expected_name'\n\n    \u001B[94mdef\u001B[39;49;00m \u001B[92massert_column_equality\u001B[39;49;00m(df, col_name1, col_name2):\n        elements = df.select(col_name1, col_name2).collect()\n        colName1Elements = \u001B[96mlist\u001B[39;49;00m(\u001B[96mmap\u001B[39;49;00m(\u001B[94mlambda\u001B[39;49;00m x: x[\u001B[94m0\u001B[39;49;00m], elements))\n        colName2Elements = \u001B[96mlist\u001B[39;49;00m(\u001B[96mmap\u001B[39;49;00m(\u001B[94mlambda\u001B[39;49;00m x: x[\u001B[94m1\u001B[39;49;00m], elements))\n        \u001B[94mif\u001B[39;49;00m colName1Elements != colName2Elements:\n            zipped = \u001B[96mlist\u001B[39;49;00m(\u001B[96mzip\u001B[39;49;00m(colName1Elements, colName2Elements))\n            t = PrettyTable([col_name1, col_name2])\n            \u001B[94mfor\u001B[39;49;00m elements \u001B[95min\u001B[39;49;00m zipped:\n                \u001B[94mif\u001B[39;49;00m elements[\u001B[94m0\u001B[39;49;00m] == elements[\u001B[94m1\u001B[39;49;00m]:\n                    first = bcolors.LightBlue + \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m0\u001B[39;49;00m]) + bcolors.LightRed\n                    second = bcolors.LightBlue + \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m1\u001B[39;49;00m]) + bcolors.LightRed\n                    t.add_row([first, second])\n                \u001B[94melse\u001B[39;49;00m:\n                    t.add_row([\u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m0\u001B[39;49;00m]), \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m1\u001B[39;49;00m])])\n>           \u001B[94mraise\u001B[39;49;00m ColumnsNotEqualError(\u001B[33m\"\u001B[39;49;00m\u001B[33m\\n\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m + t.get_string())\n\u001B[1m\u001B[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001B[0m\n\u001B[1m\u001B[31mE           +------------+---------------+\u001B[0m\n\u001B[1m\u001B[31mE           | clean_name | expected_name |\u001B[0m\n\u001B[1m\u001B[31mE           +------------+---------------+\u001B[0m\n\u001B[1m\u001B[31mE           |   matt7    |      matt     |\u001B[0m\n\u001B[1m\u001B[31mE           |    \u001B[34mbill\u001B[31m    |      \u001B[34mbill\u001B[31m     |\u001B[0m\n\u001B[1m\u001B[31mE           |  \u001B[34misabela\u001B[31m   |    \u001B[34misabela\u001B[31m    |\u001B[0m\n\u001B[1m\u001B[31mE           |    \u001B[34mNone\u001B[31m    |      \u001B[34mNone\u001B[31m     |\u001B[0m\n\u001B[1m\u001B[31mE           +------------+---------------+\u001B[0m\n\n\u001B[1m\u001B[31m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/column_comparer.py\u001B[0m:24: ColumnsNotEqualError\n\u001B[36m\u001B[1m=========================== short test summary info ============================\u001B[0m\n\u001B[31mFAILED\u001B[0m tests/chispa/test_chispa_column_equality.py::\u001B[1mtest_remove_non_word_characters_nice_error\u001B[0m - chispa.column_comparer.ColumnsNotEqualError: \n\u001B[31m========================= \u001B[31m\u001B[1m1 failed\u001B[0m, \u001B[32m1 passed\u001B[0m\u001B[31m in 0.88s\u001B[0m\u001B[31m ==========================\u001B[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2786918639959407>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mrun_pytest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtests/chispa/test_chispa_column_equality.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m<command-2770700997875077>, line 28\u001B[0m, in \u001B[0;36mrun_pytest\u001B[0;34m(pytest_path)\u001B[0m\n",
       "\u001B[1;32m     25\u001B[0m retcode \u001B[38;5;241m=\u001B[39m pytest\u001B[38;5;241m.\u001B[39mmain([pytest_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-p\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno:cacheprovider\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Fail the cell execution if we have any test failures.\u001B[39;00m\n",
       "\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m retcode \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe pytest invocation failed. See the log above for details.\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\n",
       "\u001B[0;31mAssertionError\u001B[0m: The pytest invocation failed. See the log above for details."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-2786918639959407>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrun_pytest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtests/chispa/test_chispa_column_equality.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m<command-2770700997875077>, line 28\u001B[0m, in \u001B[0;36mrun_pytest\u001B[0;34m(pytest_path)\u001B[0m\n\u001B[1;32m     25\u001B[0m retcode \u001B[38;5;241m=\u001B[39m pytest\u001B[38;5;241m.\u001B[39mmain([pytest_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-p\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno:cacheprovider\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Fail the cell execution if we have any test failures.\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m retcode \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe pytest invocation failed. See the log above for details.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\n\u001B[0;31mAssertionError\u001B[0m: The pytest invocation failed. See the log above for details.",
       "errorSummary": "<span class='ansi-red-fg'>AssertionError</span>: The pytest invocation failed. See the log above for details.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_column_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad6ce26a-7a98-4e3b-aa81-0749aba03e94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Approximate column equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493c47f2-92e7-4c7b-903e-cb707823ff5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts ==============================\u001B[0m\nplatform linux -- Python 3.10.12, pytest-7.2.0, pluggy-1.0.0\nrootdir: /Workspace/Repos/dustin.vannoy@databricks.com/notebook-best-practices, configfile: pytest.ini\nplugins: anyio-3.5.0, typeguard-2.13.3\ncollected 2 items\n\ntests/chispa/test_chispa_approx_column_equality.py \u001B[32m.\u001B[0m\u001B[31mF\u001B[0m\u001B[31m                    [100%]\u001B[0m\n\n=================================== FAILURES ===================================\n\u001B[31m\u001B[1m______________________ test_approx_col_equality_different ______________________\u001B[0m\n\n    \u001B[94mdef\u001B[39;49;00m \u001B[92mtest_approx_col_equality_different\u001B[39;49;00m():\n        data = [\n            (\u001B[94m1.1\u001B[39;49;00m, \u001B[94m1.1\u001B[39;49;00m),\n            (\u001B[94m2.2\u001B[39;49;00m, \u001B[94m2.15\u001B[39;49;00m),\n            (\u001B[94m3.3\u001B[39;49;00m, \u001B[94m5.0\u001B[39;49;00m),\n            (\u001B[94mNone\u001B[39;49;00m, \u001B[94mNone\u001B[39;49;00m)\n        ]\n        df = spark.createDataFrame(data, [\u001B[33m\"\u001B[39;49;00m\u001B[33mnum1\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mnum2\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\n>       assert_approx_column_equality(df, \u001B[33m\"\u001B[39;49;00m\u001B[33mnum1\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mnum2\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[94m0.1\u001B[39;49;00m)\n\n\u001B[1m\u001B[31mtests/chispa/test_chispa_approx_column_equality.py\u001B[0m:33: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndf = DataFrame[num1: double, num2: double], col_name1 = 'num1'\ncol_name2 = 'num2', precision = 0.1\n\n    \u001B[94mdef\u001B[39;49;00m \u001B[92massert_approx_column_equality\u001B[39;49;00m(df, col_name1, col_name2, precision):\n        elements = df.select(col_name1, col_name2).collect()\n        colName1Elements = \u001B[96mlist\u001B[39;49;00m(\u001B[96mmap\u001B[39;49;00m(\u001B[94mlambda\u001B[39;49;00m x: x[\u001B[94m0\u001B[39;49;00m], elements))\n        colName2Elements = \u001B[96mlist\u001B[39;49;00m(\u001B[96mmap\u001B[39;49;00m(\u001B[94mlambda\u001B[39;49;00m x: x[\u001B[94m1\u001B[39;49;00m], elements))\n        all_rows_equal = \u001B[94mTrue\u001B[39;49;00m\n        zipped = \u001B[96mlist\u001B[39;49;00m(\u001B[96mzip\u001B[39;49;00m(colName1Elements, colName2Elements))\n        t = PrettyTable([col_name1, col_name2])\n        \u001B[94mfor\u001B[39;49;00m elements \u001B[95min\u001B[39;49;00m zipped:\n            first = bcolors.LightBlue + \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m0\u001B[39;49;00m]) + bcolors.LightRed\n            second = bcolors.LightBlue + \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m1\u001B[39;49;00m]) + bcolors.LightRed\n            \u001B[90m# when one is None and the other isn't, they're not equal\u001B[39;49;00m\n            \u001B[94mif\u001B[39;49;00m (elements[\u001B[94m0\u001B[39;49;00m] == \u001B[94mNone\u001B[39;49;00m \u001B[95mand\u001B[39;49;00m elements[\u001B[94m1\u001B[39;49;00m] != \u001B[94mNone\u001B[39;49;00m) \u001B[95mor\u001B[39;49;00m (elements[\u001B[94m0\u001B[39;49;00m] != \u001B[94mNone\u001B[39;49;00m \u001B[95mand\u001B[39;49;00m elements[\u001B[94m1\u001B[39;49;00m] == \u001B[94mNone\u001B[39;49;00m):\n                all_rows_equal = \u001B[94mFalse\u001B[39;49;00m\n                t.add_row([\u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m0\u001B[39;49;00m]), \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m1\u001B[39;49;00m])])\n            \u001B[90m# when both are None, they're equal\u001B[39;49;00m\n            \u001B[94melif\u001B[39;49;00m elements[\u001B[94m0\u001B[39;49;00m] == \u001B[94mNone\u001B[39;49;00m \u001B[95mand\u001B[39;49;00m elements[\u001B[94m1\u001B[39;49;00m] == \u001B[94mNone\u001B[39;49;00m:\n                t.add_row([first, second])\n            \u001B[90m# when the diff is less than the threshhold, they're approximately equal\u001B[39;49;00m\n            \u001B[94melif\u001B[39;49;00m \u001B[96mabs\u001B[39;49;00m(elements[\u001B[94m0\u001B[39;49;00m] - elements[\u001B[94m1\u001B[39;49;00m]) < precision:\n                t.add_row([first, second])\n            \u001B[90m# otherwise, they're not equal\u001B[39;49;00m\n            \u001B[94melse\u001B[39;49;00m:\n                all_rows_equal = \u001B[94mFalse\u001B[39;49;00m\n                t.add_row([\u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m0\u001B[39;49;00m]), \u001B[96mstr\u001B[39;49;00m(elements[\u001B[94m1\u001B[39;49;00m])])\n        \u001B[94mif\u001B[39;49;00m all_rows_equal == \u001B[94mFalse\u001B[39;49;00m:\n>           \u001B[94mraise\u001B[39;49;00m ColumnsNotEqualError(\u001B[33m\"\u001B[39;49;00m\u001B[33m\\n\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m + t.get_string())\n\u001B[1m\u001B[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001B[0m\n\u001B[1m\u001B[31mE           +------+------+\u001B[0m\n\u001B[1m\u001B[31mE           | num1 | num2 |\u001B[0m\n\u001B[1m\u001B[31mE           +------+------+\u001B[0m\n\u001B[1m\u001B[31mE           | \u001B[34m1.1\u001B[31m  | \u001B[34m1.1\u001B[31m  |\u001B[0m\n\u001B[1m\u001B[31mE           | \u001B[34m2.2\u001B[31m  | \u001B[34m2.15\u001B[31m |\u001B[0m\n\u001B[1m\u001B[31mE           | 3.3  | 5.0  |\u001B[0m\n\u001B[1m\u001B[31mE           | \u001B[34mNone\u001B[31m | \u001B[34mNone\u001B[31m |\u001B[0m\n\u001B[1m\u001B[31mE           +------+------+\u001B[0m\n\n\u001B[1m\u001B[31m/local_disk0/.ephemeral_nfs/envs/pythonEnv-79fda558-daa4-4fe6-bb75-9a5c3be82218/lib/python3.10/site-packages/chispa/column_comparer.py\u001B[0m:52: ColumnsNotEqualError\n\u001B[36m\u001B[1m=========================== short test summary info ============================\u001B[0m\n\u001B[31mFAILED\u001B[0m tests/chispa/test_chispa_approx_column_equality.py::\u001B[1mtest_approx_col_equality_different\u001B[0m - chispa.column_comparer.ColumnsNotEqualError: \n\u001B[31m========================= \u001B[31m\u001B[1m1 failed\u001B[0m, \u001B[32m1 passed\u001B[0m\u001B[31m in 0.79s\u001B[0m\u001B[31m ==========================\u001B[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2786918639959410>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mrun_pytest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtests/chispa/test_chispa_approx_column_equality.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m<command-2770700997875077>, line 28\u001B[0m, in \u001B[0;36mrun_pytest\u001B[0;34m(pytest_path)\u001B[0m\n",
       "\u001B[1;32m     25\u001B[0m retcode \u001B[38;5;241m=\u001B[39m pytest\u001B[38;5;241m.\u001B[39mmain([pytest_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-p\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno:cacheprovider\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Fail the cell execution if we have any test failures.\u001B[39;00m\n",
       "\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m retcode \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe pytest invocation failed. See the log above for details.\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\n",
       "\u001B[0;31mAssertionError\u001B[0m: The pytest invocation failed. See the log above for details."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-2786918639959410>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrun_pytest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtests/chispa/test_chispa_approx_column_equality.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m<command-2770700997875077>, line 28\u001B[0m, in \u001B[0;36mrun_pytest\u001B[0;34m(pytest_path)\u001B[0m\n\u001B[1;32m     25\u001B[0m retcode \u001B[38;5;241m=\u001B[39m pytest\u001B[38;5;241m.\u001B[39mmain([pytest_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-p\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno:cacheprovider\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Fail the cell execution if we have any test failures.\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m retcode \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe pytest invocation failed. See the log above for details.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\n\u001B[0;31mAssertionError\u001B[0m: The pytest invocation failed. See the log above for details.",
       "errorSummary": "<span class='ansi-red-fg'>AssertionError</span>: The pytest invocation failed. See the log above for details.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_approx_column_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea36e0cd-e357-4441-ad0f-f10c2412ba6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DataFrame equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2086ce99-f049-4012-96a5-7521e274517f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_df_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8318ce67-bd45-45ea-8acb-c467064ed25b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Approximate DataFrame quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cda1f08a-0116-4cd7-8501-f8794240d962",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_approx_df_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e43b672c-3fa9-425a-b89d-69600a7d9810",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using PySpark native tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05ef36b4-18a9-4ffa-93c1-e86f206e2655",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `assertDataFrameEqual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0beab06-387f-4ece-a3ba-58c1c7feeeeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ba6fd8d-18dd-4ac7-88ea-827078b2652c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `assertPandasOnSparkEqual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3fd1a6-c018-4d00-bf99-eb7651bba371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3bffd30-9bab-48a0-acc6-ec9f07b67668",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `assertSchemaEqual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36cd85d2-79cd-46d9-b77f-99aaa2d90b77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91cb3ce4-eefb-4174-b769-ecba2bf10a25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "When should I write unit tests?\n",
    "\n",
    "When first working on a project we often prototype our code without paying attention to how we will modularize it and test it.  This can be fine during the early phases, but writing modular code and writing good tests go hand in hand. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "run_unit_tests_chispa",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
