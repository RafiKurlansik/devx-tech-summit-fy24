{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d054513a-ce6b-48a9-9c62-948aefd97971",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Unit tests in PySpark \n",
    "\n",
    "---\n",
    "<img align=\"right\" src=\"https://media3.giphy.com/media/fRYeEj3DtgrW9VpVWs/giphy.gif?cid=ecf05e47cdpuxkms9stljb9g0axvahcqt1rr5ewhzfrpxvsm&ep=v1_gifs_search&rid=giphy.gif&ct=g\" width=\"250\" height=\"300\"> \n",
    "\n",
    "\n",
    "Testing is a crucial part of software development that helps in identifying issues with your code early and often, thereby ensuring the reliability and robustness of the application. Unit tests are designed to test the independent pieces of logic that comprise your application. In general, tests look to validate that your logic is functioning as intended. By asserting that the actual output of our logic is identical to the expected output, we can determine if the logic has been implemented correctly. Ideally each test will cover exactly one piece of functionality, e.g., a specific data transformation or helper function.\n",
    "\n",
    "___\n",
    "\n",
    " \n",
    " In the context of PySpark tests are usually centered around **comparing DataFrames** for expected output.  There are several dimensions by which DataFrames can be compared:\n",
    " <br><br>\n",
    " \n",
    " * Schemas\n",
    " * Columns\n",
    " * Rows \n",
    " * Entire DataFrames\n",
    "\n",
    "In this notebook, we are going to learn about unit testing PySpark applications using the Python `pytest` framework. Tests will be written using the popular [`chispa`](https://github.com/MrPowers/chispa) library as well as the new [PySpark native testing functions available in Spark 3.5](https://issues.apache.org/jira/browse/SPARK-44042). This tutorial is designed to keep it simple, so if you want to learn more about how `pytest` works we recommend taking a closer look at [the official documentation](https://docs.pytest.org/en/7.4.x/).\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "209108c6-8c7b-400d-ab66-8c423a445e31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Working with `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f285c77-8429-4749-b045-a39867575a2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## How to structure your project with pytest\n",
    "Consider the following hypothetical project structure for a simple reporting use case:\n",
    "\n",
    "```\n",
    "├── notebooks/\n",
    "│   ├── analysis.ipynb   # report with visualizations\n",
    "├── src/\n",
    "│   ├── load_config.py   # helper functions\n",
    "│   └── cleaning.py\n",
    "├── tests/\n",
    "│   ├── main_test.py     # unit tests\n",
    "├── requirements.txt     # dependencies\n",
    "└── test-requirements.txt\n",
    "```\n",
    "\n",
    "The `notebooks/` folder contains `analysis.ipynb`, which reports on and visualizes some business data.  This notebook imports custom Python functions from both files in `src/` to help load and clean data like so:\n",
    "\n",
    "```\n",
    "from src.load_config import db_loader, config_handler\n",
    "from src.cleaning import *\n",
    "```\n",
    "\n",
    "Since our report depends on these functions to get and prepare the data correctly, we want to write tests that validate our functions are behaving as intended.  To so do, we create a `tests/` folder and include our tests there.  **`pytest` is designed to look for folders and files with \"test\" as a prefix or suffix.**  In this example our test script is called `main_test.py`, but later on you will see examples like `test_pyspark_column_equality.py`.  Both are supported and will be picked up by `pytest`. \n",
    "\n",
    "The last two files in our project are specify any dependencies for all of our code.  It is a best practice to separate testing dependencies, since we only need `pytest` to run the testing scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e774a9bf-0c07-4aed-a99d-ba01b910d9cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Installing dependencies\n",
    "To use `pytest` we will need to install it alongside any other dependencies, then restart the Python interpreter to make them available in our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fe0a48e-a04f-4099-b876-20bb82eab237",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!cp ../requirements.txt ~/.\n",
    "%pip install -r ~/requirements.txt\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25e44968-8f39-46aa-821f-244fab29d402",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Invoking `pytest`\n",
    "\n",
    "`pytest` is usually run from the system command line, but it can also be executed from the context of a notebook or Python REPL.  We'll be using the latter method to invoke our tests from the Databricks editor.  This lets us make use of Spark and other configuration variables in Databricks Runtime. \n",
    "\n",
    "One limitation of this approach is that changes to the test will be cached by Python's import caching mechanism.  If we wanted to iterate on tests during a development scenario, we would need to use `dbutils.library.restartPython()` to clear the cache and pick up changes to our tests.  This tutorial has been structured to render this unnecessary, but it is important to note!\n",
    "\n",
    "In the following cell, we first make sure that all tests will run relative to our repository root directory.  Then we define `run_pytest`, a helper function to invoke a specific test file in our project.  Importantly, **this function also fails the Databricks notebook cell execution if tests fail.**  This ensures we surface errors whether we run these unit tests in an interactive session or as part of a Databricks Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e4d1408-8fda-45c2-a849-6270eae2db29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Run all tests in the repository root.\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "repo_root = os.path.dirname(os.path.dirname(notebook_path))\n",
    "os.chdir(f'/Workspace/{repo_root}')\n",
    "%pwd\n",
    "\n",
    "def run_pytest(pytest_path):\n",
    "  # Skip writing pyc files on a readonly filesystem.\n",
    "  sys.dont_write_bytecode = True\n",
    "\n",
    "  retcode = pytest.main([pytest_path, \"-p\", \"no:cacheprovider\"])\n",
    "\n",
    "  # Fail the cell execution if we have any test failures.\n",
    "  assert retcode == 0, 'The pytest invocation failed. See the log above for details.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c69b4a6-9722-44ed-9d9d-8bc54b5db702",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test scenarios\n",
    "Before we use `run_pytest()`, let's take a closer look at how `chispa` works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "262313ae-263a-42e1-86fd-deb83b683b38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using `chispa`\n",
    "\n",
    "`chispa` is Python library for testing PySpark code.  It is authored by Matthew Powers, who is currently (September 2023) at Databricks.  There are three main functions to compare DataFrames in `chispa`:\n",
    "\n",
    "* `assert_df_equality()`\n",
    "* `assert_column_equality()`\n",
    "* `assert_approx_df_equality()`\n",
    "* `assert_approx_column_equality()`\n",
    "\n",
    "**In this section we will focus on various ways to compare DataFrames using `assert_df_equality()`**, and we've included some additional tests using the other functions at the end of this section.  If you want to learn more about the library, be sure to checkout [the official documentation](https://mrpowers.github.io/chispa/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93166279-208c-40ee-85ee-c25b4433dea8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DataFrame equality\n",
    "\n",
    "A common data transformation task is to add or remove columns from DataFrames.  To validate that our transformations are working as intended, we can assert that the actual output DataFrame of a function is equivalent to an expected output DataFrame.  We will use this approach to test DataFrame equality for schemas, columns, as well as row or column orders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8412303a-85c6-41aa-b428-10a1cd32881d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Schema equality\n",
    "\n",
    "Check out the example below where we compare two different DataFrames, one with all numeric columns and one with a mix of numeric and string columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f378b29b-5806-4b5e-a501-22e570f5324a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chispa import assert_df_equality\n",
    "# DF with numeric and string columns\n",
    "data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "data2 = [\n",
    "        (1, 6),\n",
    "        (2, 7),\n",
    "        (3, 8),\n",
    "        (None, None)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(data2, [\"num\", \"num2\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c66d65d-2971-414d-8959-f6f26f7183e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we expected, this fails.  `chispa` makes it really clear exactly why it failed, too, specifying the precise column differences and highlighting the discrepancies in red. \n",
    "\n",
    "**Let's run another comparison, but make sure that the schemas match.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c07e5cae-5d53-48c9-85e6-d1f91b45d87f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chispa import assert_df_equality\n",
    "# DF with numeric and string columns\n",
    "data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "data2 = [\n",
    "        (1, \"d\"),\n",
    "        (2, \"e\"),\n",
    "        (3, \"f\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(data2, [\"num\", \"letter\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0348766-6d8c-4924-86d9-bce88b243db3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Aha! The schemas match but the DataFrames are not 100% equal.  Let's try this one more time and ensure that the DataFrames are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97f83ce0-3d20-4139-b4e9-becb193cb231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chispa import assert_df_equality\n",
    "# DF with numeric and string columns\n",
    "data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "data2 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(data2, [\"num\", \"letter\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3503773-c3da-44c8-bf58-8550755597d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "`chispa` will not return any output to the console when we run tests this way.  However, when we use `chispa` in combination with `pytest`, we will always get a complete report on how our tests fared.  To do so, we have added `tests/test_chispa_101.py` to our project.  This file contains the exact same test that we ran in the cell above, the only exception being that we wrap it in a function:\n",
    "\n",
    "```{python}\n",
    "## contents of tests/chispa/test_chispa_101.py\n",
    "\n",
    "def test_schema_mismatch_message():\n",
    "    # DF with numeric and string columns\n",
    "    data1 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "    df1 = spark.createDataFrame(data1, [\"num\", \"letter\"])\n",
    "    \n",
    "    # DF with only numeric columns\n",
    "    data2 = [\n",
    "        (1, \"a\"),\n",
    "        (2, \"b\"),\n",
    "        (3, \"c\"),\n",
    "        (None, None)\n",
    "    ]\n",
    "    df2 = spark.createDataFrame(data2, [\"num\", \"letter\"])\n",
    "    \n",
    "    # Compare them\n",
    "    assert_df_equality(df1, df2)\n",
    "```\n",
    "\n",
    "Let's invoke this test now using `pytest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b782cfe0-719f-44f5-adfd-2e1c85446195",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_101.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8facf3c9-6183-4255-9768-69ba53a079ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now that we understand how to combine `chispa` with `pytest`, let's examine some other test scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91c67837-4bcf-488b-a64d-ebf0135bcee9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Column equality\n",
    "\n",
    "In addition to adding or removing columns, a common data transformation is to update the contents of a column.  Let's take a slightly more realistic example for this case.  \n",
    "\n",
    "In this project under `src/transforms_spark.py` we have a helper function called `remove_non_word_characters()` which ... you guessed it, strips all non-word characters from the strings in each row:\n",
    "\n",
    "```\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Removing all non-word characters in PySpark\n",
    "def remove_non_word_characters(col):\n",
    "    return F.regexp_replace(col, \"[^\\\\w\\\\s]+\", \"\")\n",
    "```\n",
    "\n",
    "To test this unit of logic, we will take three simple steps.\n",
    "\n",
    "1. Create a DataFrame with rows that have non-word characters\n",
    "2. Apply `remove_non_word_characters()` to the DataFrame and generate a new column with clean rows\n",
    "3. Compare this DataFrame to a 2nd DataFrame with the expected output and assert that the two are equal\n",
    "\n",
    "The following cell does just that by importing `remove_non_word_characters()` from the `src` folder in our project and applying it to some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316b9213-87ee-49cf-9226-c167f7d30701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from src.transforms_spark import remove_non_word_characters\n",
    "from chispa import assert_column_equality\n",
    "\n",
    "# Dirty rows\n",
    "dirty_rows = [\n",
    "      (\"jo&&se\",),\n",
    "      (\"**li**\",),\n",
    "      (\"#::luisa\",),\n",
    "      (None,)\n",
    "  ]\n",
    "source_df = spark.createDataFrame(dirty_rows, [\"name\"])\n",
    "\n",
    "# Cleaned rows using function\n",
    "clean_df = source_df.withColumn(\n",
    "    \"clean_name\",\n",
    "    remove_non_word_characters(F.col(\"name\"))\n",
    ")\n",
    "\n",
    "# Expected output, should be identical to clean_df\n",
    "expected_data = [\n",
    "      (\"jo&&se\", \"jose\"),\n",
    "      (\"**li**\", \"li\"),\n",
    "      (\"#::luisa\", \"luisa\"),\n",
    "      (None, None)\n",
    "  ]\n",
    "expected_df = spark.createDataFrame(expected_data, [\"name\", \"clean_name\"])\n",
    "\n",
    "assert_df_equality(clean_df, expected_df, underline_cells=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2eccecd-762c-4d94-92a2-91fab6b33749",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looks good.  Before we invoke this test, let's consider another case:\n",
    "\n",
    "```\n",
    "data = [\n",
    "        (\"matt7\", \"matt\"),\n",
    "        (\"bill&\", \"bill\"),\n",
    "        (\"isabela*\", \"isabela\"),\n",
    "        (None, None)\n",
    "      ]\n",
    "```\n",
    "\n",
    "We have included this test case in `tests/chispa/test_chispa_column_equality.py`. In that file we import `remove_non_word_characters()` just like we did in the previous cell. \n",
    "\n",
    "Using the definition of `remove_non_word_characters()` from earlier, do you think this test will pass?  Why or why not?  Think about this before invoking `pytest` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ae3d6ff-605a-4089-a74d-d2629f641534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_column_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b27f09b-bd24-41cf-b660-4b2207ce2b56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Our test results reflect the fact that our logic might not have been working exactly as intended!  To get clean data, we would need to modify `remove_non_word_characters()` to include integers.  \n",
    "\n",
    "This example illustrates the importance of unit testing.  The author of this function used an incomplete regular expression to clean their text data, which could have been tricky to track down after the fact.  By including more test cases - the integer in the string - we ensure the quality and robustness of our code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69ebf14f-8629-4000-8070-4210804ff541",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Row and column order\n",
    "Sometimes pipelines or analytics depend on row or column order.  `assert_df_equality()` assumes that equality extends to row and column order.  This can be overridden using the `ignore_row_order` or `ignore_column_order` parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25a76297-14a2-42a9-9ab5-5d346104d834",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chispa import assert_df_equality\n",
    "\n",
    "# DF with numeric and string columns\n",
    "row_order1 = [\n",
    "        (1,),\n",
    "        (2,),\n",
    "        (3,),\n",
    "        (None,)\n",
    "    ]\n",
    "df1 = spark.createDataFrame(row_order1, [\"num\"])\n",
    "\n",
    "# DF with only numeric columns\n",
    "row_order2 = [\n",
    "        (3,),\n",
    "        (2,),\n",
    "        (1,),\n",
    "        (None,)\n",
    "    ]\n",
    "df2 = spark.createDataFrame(row_order2, [\"num\"])\n",
    "\n",
    "# Compare them\n",
    "assert_df_equality(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83ef693b-9828-404d-b8ff-ddca6aed77a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As expected, these DataFrames are not identical and our tests fails.  Let's try again, but ignore row order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c3d523b-b3fc-4a1b-89da-2b2089fa0690",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert_df_equality(df1, df2, ignore_row_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "759d594b-f00a-49cc-a469-9bbcc15ca09b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The content of the DataFrames are identical, even if the order is not, and our test passes.\n",
    "___\n",
    "\n",
    "The remaining tests with `chispa` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad6ce26a-7a98-4e3b-aa81-0749aba03e94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Approximate equality\n",
    "When dealing with floating point precision, it can be useful to test for approximate equality.  The sensitivity of this approximation can be set using the `precision` argument in `assert_approx_df_equality()` or `assert_approx_column_equality()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73bf9d03-44bf-4693-8224-e25d398f34ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Approximate column equality\n",
    "\n",
    "For example, assume we have the following DataFrame with two floating point columns.\n",
    "\n",
    "```\n",
    "data = [\n",
    "    (1.1, 1.1),\n",
    "    (2.2, 2.15),\n",
    "    (3.3, 3.37),\n",
    "    (None, None)\n",
    "    ]\n",
    "df = spark.createDataFrame(data, [\"num1\", \"num2\"])\n",
    "\n",
    "assert_approx_column_equality(df, \"num1\", \"num2\", precision=0.1)\n",
    "```\n",
    "\n",
    "A precision of 0.1 will determine these columns to be identical.  If we set precision to 0.01, `chispa` would fail the assertion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30f9dedf-e8b1-49df-b471-2268b760ddb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chispa import assert_approx_column_equality\n",
    "\n",
    "# Create DataFrame with two columns of floating point numbers\n",
    "data = [\n",
    "    (1.1, 1.1),\n",
    "    (2.2, 2.15),\n",
    "    (3.3, 3.37),\n",
    "    (None, None)\n",
    "    ]\n",
    "df = spark.createDataFrame(data, [\"num1\", \"num2\"])\n",
    "\n",
    "# Compare them with thousandths-level precision\n",
    "assert_approx_column_equality(df, \"num1\", \"num2\", precision=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ac950f2-9617-4d92-a1d8-a9c753230893",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's invoke this test via `pytest` and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e44736-2b14-4759-93b1-4d31f24ef5ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_approx_column_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d017588-7793-4f70-8e60-3642678c2b06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Take a moment to consider why this test failed? What would need to change in order for it to pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ca31ad8-f8eb-49c5-8a69-598ad61f6d2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Approximate DataFrame quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b28e45a-fff7-480a-8ab9-af29510e2cca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/chispa/test_chispa_approx_df_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e43b672c-3fa9-425a-b89d-69600a7d9810",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using PySpark native tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05ef36b4-18a9-4ffa-93c1-e86f206e2655",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `assertDataFrameEqual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0beab06-387f-4ece-a3ba-58c1c7feeeeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from src.transforms_spark import remove_non_word_characters\n",
    "from pyspark.testing.utils import assertDataFrameEqual\n",
    "\n",
    "# Dirty rows\n",
    "dirty_rows = [\n",
    "      (\"jo&&se\",),\n",
    "      (\"**li**\",),\n",
    "      (\"#::luisa\",),\n",
    "      (None,)\n",
    "  ]\n",
    "source_df = spark.createDataFrame(dirty_rows, [\"name\"])\n",
    "\n",
    "# Cleaned rows using function\n",
    "clean_df = source_df.withColumn(\n",
    "    \"clean_name\",\n",
    "    remove_non_word_characters(F.col(\"name\"))\n",
    ")\n",
    "\n",
    "# Expected output, should be identical to clean_df\n",
    "expected_data = [\n",
    "      (\"jo&&se\", \"jose\"),\n",
    "      (\"**li**\", \"li\"),\n",
    "      (\"#::luisa\", \"luisa\"),\n",
    "      (None, None)\n",
    "  ]\n",
    "expected_df = spark.createDataFrame(expected_data, [\"name\", \"clean_name\"])\n",
    "\n",
    "assertDataFrameEqual(clean_df, expected_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da551cc7-7860-470d-ab6c-1ec4456e51a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's run the same test as before where we had an integer mixed with the strings, but we'll use the `assertDataFrameEqual` function instead of one from `chispa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e18fec1e-6b38-4cb3-a3b3-c81572025b05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_pytest(\"tests/pyspark_native/test_df_equality.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ba6fd8d-18dd-4ac7-88ea-827078b2652c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `assertPandasOnSparkEqual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3fd1a6-c018-4d00-bf99-eb7651bba371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3bffd30-9bab-48a0-acc6-ec9f07b67668",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `assertSchemaEqual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36cd85d2-79cd-46d9-b77f-99aaa2d90b77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "run_unit_tests_chispa",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
